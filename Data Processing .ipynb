{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6146d585-6a42-4a48-b68e-b64935cd6f1e",
   "metadata": {},
   "source": [
    "Based on (Dựa trên: https://www.kaggle.com/code/sudalairajkumar/getting-started-with-text-preprocessing) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a07ff1c-4f6f-467a-ace3-30da12eaae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import emoji_vietnamese as ev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfad43-35c4-431b-9571-d19594fd0016",
   "metadata": {},
   "source": [
    "# Import thư viện pyvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa62d85e-2033-4e7a-8d88-a628401a5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvi import ViTokenizer, ViPosTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9dad85-716c-4dbd-b50d-3938d46e2683",
   "metadata": {},
   "source": [
    "# Bảng nguyên âm tiếng Việt và cách mã hóa chúng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3214afb3-e1a0-4cf9-b19a-d44b5929be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bang_nguyen_am = [['a', 'à', 'á', 'ả', 'ã', 'ạ', 'a'],\n",
    "                  ['ă', 'ằ', 'ắ', 'ẳ', 'ẵ', 'ặ', 'aw'],\n",
    "                  ['â', 'ầ', 'ấ', 'ẩ', 'ẫ', 'ậ', 'aa'],\n",
    "                  ['e', 'è', 'é', 'ẻ', 'ẽ', 'ẹ', 'e'],\n",
    "                  ['ê', 'ề', 'ế', 'ể', 'ễ', 'ệ', 'ee'],\n",
    "                  ['i', 'ì', 'í', 'ỉ', 'ĩ', 'ị', 'i'],\n",
    "                  ['o', 'ò', 'ó', 'ỏ', 'õ', 'ọ', 'o'],\n",
    "                  ['ô', 'ồ', 'ố', 'ổ', 'ỗ', 'ộ', 'oo'],\n",
    "                  ['ơ', 'ờ', 'ớ', 'ở', 'ỡ', 'ợ', 'ow'],\n",
    "                  ['u', 'ù', 'ú', 'ủ', 'ũ', 'ụ', 'u'],\n",
    "                  ['ư', 'ừ', 'ứ', 'ử', 'ữ', 'ự', 'uw'],\n",
    "                  ['y', 'ỳ', 'ý', 'ỷ', 'ỹ', 'ỵ', 'y']]\n",
    "\n",
    "bang_ky_tu_dau = ['', 'f', 's', 'r', 'x', 'j']\n",
    "nguyen_am_to_ids = {}\n",
    "\n",
    "# Ánh xạ nguyên âm và mã hóa dấu\n",
    "for i in range(len(bang_nguyen_am)):\n",
    "    for j in range(len(bang_nguyen_am[i]) - 1):\n",
    "        nguyen_am_to_ids[bang_nguyen_am[i][j]] = (i, j)\n",
    "\n",
    "# Chuẩn hóa unicode tổ hợp về dạng NFC\n",
    "def chuan_hoa_unicode(text):\n",
    "    text = unicodedata.normalize('NFC', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001f6c74-6999-40b7-b34e-faa283080782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra từ có hợp lệ hay không\n",
    "def is_valid_vietnam_word(word):\n",
    "    chars = list(word)\n",
    "    nguyen_am_index = -1\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x != -1:\n",
    "            if nguyen_am_index == -1:\n",
    "                nguyen_am_index = index\n",
    "            else:\n",
    "                if index - nguyen_am_index != 1:\n",
    "                    return False\n",
    "                nguyen_am_index = index\n",
    "    return True\n",
    "\n",
    "# Chuẩn hóa dấu cho từ tiếng Việt\n",
    "# Chuyển câu văn về cách gõ dấu kiểu cũ: dùng òa úy thay oà uý\n",
    "# Xem tại đây: https://vi.wikipedia.org/wiki/Quy_tắc_đặt_dấu_thanh_trong_chữ_quốc_ngữ\n",
    "def chuan_hoa_dau_tu_tieng_viet(word):\n",
    "    if not is_valid_vietnam_word(word):\n",
    "        return word\n",
    "\n",
    "    chars = list(word)\n",
    "    dau_cau = 0\n",
    "    nguyen_am_index = []\n",
    "    qu_or_gi = False\n",
    "\n",
    "    for index, char in enumerate(chars):\n",
    "        x, y = nguyen_am_to_ids.get(char, (-1, -1))\n",
    "        if x == -1:\n",
    "            continue\n",
    "        elif x == 9 and index != 0 and chars[index - 1] == 'q':  # Kiểm tra qu\n",
    "            chars[index] = 'u'\n",
    "            qu_or_gi = True\n",
    "        elif x == 5 and index != 0 and chars[index - 1] == 'g':  # Kiểm tra gi\n",
    "            chars[index] = 'i'\n",
    "            qu_or_gi = True\n",
    "        if y != 0:\n",
    "            dau_cau = y\n",
    "            chars[index] = bang_nguyen_am[x][0]\n",
    "        if not qu_or_gi or index != 1:\n",
    "            nguyen_am_index.append(index)\n",
    "\n",
    "    if len(nguyen_am_index) < 2:\n",
    "        if qu_or_gi:\n",
    "            if len(chars) == 2:\n",
    "                x, y = nguyen_am_to_ids.get(chars[1])\n",
    "                chars[1] = bang_nguyen_am[x][dau_cau]\n",
    "            else:\n",
    "                x, y = nguyen_am_to_ids.get(chars[2], (-1, -1))\n",
    "                if x != -1:\n",
    "                    chars[2] = bang_nguyen_am[x][dau_cau]\n",
    "                else:\n",
    "                    chars[1] = bang_nguyen_am[5][dau_cau] if chars[1] == 'i' else bang_nguyen_am[9][dau_cau]\n",
    "            return ''.join(chars)\n",
    "        return word\n",
    "\n",
    "    for index in nguyen_am_index:\n",
    "        x, y = nguyen_am_to_ids[chars[index]]\n",
    "        if x == 4 or x == 8:  # ê, ơ\n",
    "            chars[index] = bang_nguyen_am[x][dau_cau]\n",
    "            return ''.join(chars)\n",
    "\n",
    "    if len(nguyen_am_index) == 2 and nguyen_am_index[-1] == len(chars) - 1:\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[0]]]\n",
    "        chars[nguyen_am_index[0]] = bang_nguyen_am[x][dau_cau]\n",
    "    else:\n",
    "        x, y = nguyen_am_to_ids[chars[nguyen_am_index[1]]]\n",
    "        chars[nguyen_am_index[1]] = bang_nguyen_am[x][dau_cau]\n",
    "\n",
    "    return ''.join(chars)\n",
    "\n",
    "# Chuẩn hóa dấu câu\n",
    "def chuan_hoa_dau_cau_tieng_viet(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    for index, word in enumerate(words):\n",
    "        cw = re.sub(r'(^\\p{P}*)([p{L}.]*\\p{L}+)(\\p{P}*$)', r'\\1/\\2/\\3', word).split('/')\n",
    "        if len(cw) == 3:\n",
    "            cw[1] = chuan_hoa_dau_tu_tieng_viet(cw[1])\n",
    "        words[index] = ''.join(cw)\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Tách từ tiếng Việt\n",
    "# Tách các từ ghép VD : Học sinh học sinh học ⇒ Học_sinh học sinh_học\n",
    "def tach_tu_tieng_viet(text):\n",
    "    text = ViTokenizer.tokenize(text)\n",
    "    return text\n",
    "\n",
    "# Đưa về chữ viết thường\n",
    "def chuyen_chu_thuong(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Xóa các ký tự thừa, dấu câu, khoảng trắng thừa và chuẩn hóa câu\n",
    "def chuan_hoa_cau(text):\n",
    "    text = re.sub(r'[^\\s\\wáàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệóòỏõọôốồổỗộơớờởỡợíìỉĩịúùủũụưứừửữựýỳỷỹỵđ_]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "# Đổi emoji sang text\n",
    "def doi_emoji_sang_tieng_viet(text):\n",
    "    return ev.demojize(text)\n",
    "# Xóa bỏ stopword\n",
    "stopword = set()\n",
    "with open('./vietnamese-stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopword = f.read().split(\"\\n\")  # Đọc danh sách stopwords và chia dòng\n",
    "def xoa_stopwords(text):\n",
    "    words = []\n",
    "    for word in text.strip().split():\n",
    "        if word not in stopword:\n",
    "            words.append(word)\n",
    "    return ' '.join(words)\n",
    "# Xóa địa chỉ email\n",
    "def xoa_email(text):\n",
    "    # Sử dụng regex để tìm và xóa email\n",
    "    email_pattern = r'[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+'\n",
    "    return re.sub(email_pattern, '', text)\n",
    "# Hàm xóa URL\n",
    "def xoa_url(text):\n",
    "    # Biểu thức chính quy để nhận diện URL\n",
    "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    return re.sub(url_pattern, '', text)\n",
    "# Hàm xử lý tiền xử lý văn bản\n",
    "def tien_xu_li(text):\n",
    "    text = chuan_hoa_unicode(text)\n",
    "    text = xoa_email(text)\n",
    "    text = xoa_url(text)\n",
    "    text = chuan_hoa_dau_tu_tieng_viet(text)\n",
    "    #text = chuan_hoa_dau_cau_tieng_viet(text)\n",
    "    text = tach_tu_tieng_viet(text)\n",
    "    text = chuyen_chu_thuong(text)\n",
    "    text = doi_emoji_sang_tieng_viet(text)\n",
    "    text = xoa_stopwords(text)\n",
    "    text = chuan_hoa_cau(text)\n",
    "    return text\n",
    "# Hàm chuyển đổi rating thành mảng nhị phân\n",
    "def convert_rating_to_binary(rating):\n",
    "    # Bảng mapping từ số sao sang mảng nhị phân\n",
    "    rating_to_binary = {\n",
    "        5: [0, 0, 0, 0, 1],\n",
    "        4: [0, 0, 0, 1, 0],\n",
    "        3: [0, 0, 1, 0, 0],\n",
    "        2: [0, 1, 0, 0, 0],\n",
    "        1: [1, 0, 0, 0, 0]\n",
    "    }\n",
    "    return rating_to_binary.get(rating, [0, 0, 0, 0, 0])  # Nếu không có rating thì trả về [0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab977d6-53a8-4793-90f5-312f562f80e0",
   "metadata": {},
   "source": [
    "# Chương trình chính "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d90dcef1-c338-47c8-8a66-68e0a27f863d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unicodedata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Lấy cột 'CommentText' và xử lý dữ liệu\u001b[39;00m\n\u001b[0;32m      8\u001b[0m commentText \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCommentText\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Xử lý NaN bằng chuỗi trống\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m commentText_processed \u001b[38;5;241m=\u001b[39m \u001b[43mcommentText\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtien_xu_li\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRatingBinary\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRating\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(convert_rating_to_binary)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Xác định vị trí của cột 'Rating' và 'CommentText'\u001b[39;00m\n",
      "File \u001b[1;32mE:\\pytorch_base\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\pytorch_base\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\pytorch_base\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mE:\\pytorch_base\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\pytorch_base\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[8], line 124\u001b[0m, in \u001b[0;36mtien_xu_li\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtien_xu_li\u001b[39m(text):\n\u001b[1;32m--> 124\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mchuan_hoa_unicode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m     text \u001b[38;5;241m=\u001b[39m xoa_email(text)\n\u001b[0;32m    126\u001b[0m     text \u001b[38;5;241m=\u001b[39m xoa_url(text)\n",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m, in \u001b[0;36mchuan_hoa_unicode\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchuan_hoa_unicode\u001b[39m(text):\n\u001b[1;32m---> 24\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43municodedata\u001b[49m\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNFC\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unicodedata' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    file_path = './Data.csv'\n",
    "\n",
    "    # Đọc file CSV\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Lấy cột 'CommentText' và xử lý dữ liệu\n",
    "    commentText = data['CommentText'].fillna('')  # Xử lý NaN bằng chuỗi trống\n",
    "    commentText_processed = commentText.apply(tien_xu_li)\n",
    "\n",
    "    data['RatingBinary'] = data['Rating'].apply(convert_rating_to_binary)\n",
    "    # Xác định vị trí của cột 'Rating' và 'CommentText'\n",
    "    rating_column_index = data.columns.get_loc('Rating')\n",
    "    cmt_column_index = data.columns.get_loc('CommentText')\n",
    "    # Chèn cột 'RatingBinary' và 'prepCommentText'\n",
    "    data.insert(rating_column_index + 1, 'RatingBinary', data.pop('RatingBinary'))\n",
    "    data.insert(cmt_column_index + 1, 'prepCommentText', commentText_processed)\n",
    "\n",
    "    # Lưu file CSV có cột mới\n",
    "    output_file_path = './ResultData.csv'\n",
    "    data.to_csv(output_file_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    # Hiển thị kết quả\n",
    "    print(\"Ví dụ xử lý : \\n\")\n",
    "    print(commentText_processed)\n",
    "    print(\"Chuyển đổi rating thành nhị phân:\\n\")\n",
    "    print(data[['Rating', 'RatingBinary']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
